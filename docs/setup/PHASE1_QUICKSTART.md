# üöÄ Phase 1: Quick Start Guide

**‚ö†Ô∏è Note:** This is an older guide. For the most up-to-date setup instructions, see **[GETTING_STARTED.md](../GETTING_STARTED.md)**.

## Overview

Phase 1 focuses on building and validating the **ETL Pipeline with Sentiment Analysis** using NLTK. This phase does NOT include AI chat features (those come when using Ollama).

## ‚úÖ Phase 1 Components

- ‚úÖ **Kafka** - Message streaming
- ‚úÖ **PostgreSQL** - Data storage
- ‚úÖ **Flink** - Stream processing with NLTK sentiment analysis
- ‚úÖ **Producers** - News and price data ingestion
- ‚úÖ **Dashboard** - Live charts and sentiment tables
- ‚ö†Ô∏è **Ollama** - Optional (for AI Analyst feature)
- ‚ö†Ô∏è **RAG Pipeline** - Optional (for AI context)

---

## üöÄ Recommended Quick Start (2026 Method)

### ‚úÖ Use the Startup Script (Easiest)

```bash
# 1. Create .env file
cp .env.example .env
nano .env  # Add your FINNHUB_API_KEY

# 2. Run the startup script (handles everything!)
./start_data_pipeline.sh
```

**That's it!** The script automatically:
- ‚úÖ Validates environment and files
- ‚úÖ Detects Windows Host IP (for Ollama)
- ‚úÖ Starts all services with health checks
- ‚úÖ Submits Flink job
- ‚úÖ Shows detailed status

**Access Dashboard:** http://localhost:8502

---

## üìã Manual Setup (Alternative)

### 1. Setup Environment Variables

Create `.env` file:
```bash
cp .env.example .env
# Edit and add: FINNHUB_API_KEY=your_actual_api_key_here
```

### 2. Start All Services

```bash
# Start infrastructure and producers (using profiles)
docker-compose --profile producers up -d
```

This starts:
- ‚úÖ Kafka
- ‚úÖ PostgreSQL
- ‚úÖ Flink (JobManager + TaskManager)
- ‚úÖ News Producer
- ‚úÖ Price Producer
- ‚úÖ Price Consumer
- ‚úÖ RAG Ingest
- ‚úÖ Dashboard

### 3. Submit Flink Sentiment Job

```bash
# Wait 30 seconds for Flink to be ready, then:
docker exec market_jobmanager ./bin/flink run -py /opt/flink/usrlib/flink_sentiment.py
```

**‚ö†Ô∏è Important:** Use `market_jobmanager` (not `vibe_jobmanager`)

### 4. Access Dashboard

Open browser: **http://localhost:8502**

You should see:
- üìä Live price charts
- üìà Sentiment score tables

---

## ‚úÖ Phase 1 Validation Checklist

### Data Ingestion
- [ ] News producer fetching and publishing to Kafka `stock_news` topic
- [ ] Price producer fetching and publishing to Kafka `stock_prices` topic
- [ ] Price consumer writing to PostgreSQL `stock_prices` table

### Stream Processing
- [ ] Flink job running successfully (check http://localhost:8081)
- [ ] Sentiment scores appearing in `sentiment_log` table
- [ ] Sentiment scores are between -1.0 and 1.0

### Dashboard
- [ ] Dashboard accessible at http://localhost:8502
- [ ] Price charts displaying data
- [ ] Sentiment scores table showing data
- [ ] Can filter by symbol

### Database Verification

```bash
# Connect to database (correct container name!)
docker exec -it market_postgres psql -U market_user -d market_mood

# Check tables
\dt

# Check price data
SELECT COUNT(*) FROM stock_prices;
SELECT * FROM stock_prices ORDER BY timestamp DESC LIMIT 10;

# Check sentiment data
SELECT COUNT(*) FROM sentiment_log;
SELECT symbol, headline, sentiment_score FROM sentiment_log ORDER BY timestamp DESC LIMIT 10;

# Exit
\q
```

---

## üîç Monitoring

### Check Kafka Topics
```bash
# List topics
docker exec market_kafka kafka-topics --list --bootstrap-server localhost:9092

# Consume from stock_news topic
docker exec market_kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic stock_news --from-beginning --max-messages 5
```

### Check Flink Job
- Visit: http://localhost:8081
- Check "Running Jobs" section
- View job metrics and logs

### Check Container Logs
```bash
# News producer
docker logs market_news_producer --tail 20

# Price producer
docker logs market_price_producer --tail 20

# Flink
docker logs market_jobmanager --tail 20
docker logs market_taskmanager --tail 20

# Kafka
docker logs market_kafka --tail 20

# Dashboard
docker logs market_dashboard --tail 20
```

---

## üêõ Common Issues

### No Data in Dashboard
**Solution:**
1. Wait 2-3 minutes for initial data collection
2. Check if producers are running: `docker ps | grep producer`
3. Verify database has data: `SELECT COUNT(*) FROM stock_prices;`
4. See [TROUBLESHOOTING.md](../TROUBLESHOOTING.md) for comprehensive guide

### Flink Job Not Starting
**Solution:**
```bash
# Check if job is running
docker exec market_jobmanager ./bin/flink list

# If not running, submit it
docker exec market_jobmanager ./bin/flink run -py /opt/flink/usrlib/flink_sentiment.py
```

See [FLINK_JOB_GUIDE.md](../FLINK_JOB_GUIDE.md) for detailed instructions.

### Producer Connection Errors
**Solution:**
1. Verify Kafka is healthy: `docker ps | grep kafka`
2. Check FINNHUB_API_KEY is set: `grep FINNHUB .env`
3. Restart with startup script: `./start_data_pipeline.sh`

---

## üìä Expected Data Flow

```
Finnhub API
    ‚Üì
Producers (news_producer.py, price_producer.py)
    ‚Üì
Kafka Topics (stock_news, stock_prices)
    ‚Üì
Consumers (Flink job, price_consumer.py)
    ‚Üì
PostgreSQL (sentiment_log, stock_prices tables)
    ‚Üì
Streamlit Dashboard (app.py)
```

---

## üéØ Phase 1 Success Criteria

- ‚úÖ All services running without errors
- ‚úÖ Data flowing through entire pipeline
- ‚úÖ Sentiment scores calculated correctly
- ‚úÖ Dashboard displaying live data
- ‚úÖ System stable for extended period (1+ hours)

---

## üîÆ Adding Ollama (Optional)

To enable the AI Analyst feature:

1. **Install Ollama on Windows**
   ```powershell
   # Download from: https://ollama.com/
   ```

2. **Configure network access**
   ```powershell
   # Set environment variable
   setx OLLAMA_HOST "0.0.0.0:11434"
   
   # Add firewall rule (as Administrator)
   New-NetFirewallRule -DisplayName "Ollama Allow" -Direction Inbound -LocalPort 11434 -Protocol TCP -Action Allow
   ```

3. **Pull model**
   ```powershell
   ollama pull llama3
   ```

4. **Restart pipeline**
   ```bash
   ./start_data_pipeline.sh
   ```

5. **Access AI Analyst**
   - Dashboard: http://localhost:8502
   - Click "üí¨ AI Analyst" tab

See [LLM_API_INTEGRATION.md](LLM_API_INTEGRATION.md) for complete guide.

---

## üìö Related Documentation

- **[GETTING_STARTED.md](../GETTING_STARTED.md)** - ‚≠ê **Recommended** Complete modern guide
- **[TROUBLESHOOTING.md](../TROUBLESHOOTING.md)** - Comprehensive troubleshooting
- **[FLINK_JOB_GUIDE.md](../FLINK_JOB_GUIDE.md)** - Flink job management
- **[DOCKER_VS_SCRIPT_GUIDE.md](../DOCKER_VS_SCRIPT_GUIDE.md)** - Command reference
- **[DOCUMENTATION_INDEX.md](../DOCUMENTATION_INDEX.md)** - All documentation

---

**Current Phase:** Phase 1 - ETL with Sentiment Analysis  
**Status:** Production Ready  
**Last Updated:** February 2026

**For most up-to-date instructions, use: [GETTING_STARTED.md](../GETTING_STARTED.md)**
